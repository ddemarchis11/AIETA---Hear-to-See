{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83c090c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f2d8ae2064642098fb9615576baa8b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creazione Noisy Set:   0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "os.makedirs(\"mixed_up_data_talk/noisy\", exist_ok = True)\n",
    "\n",
    "VOICE_DIR = os.path.abspath(\"datasets/mathurinache/the-lj-speech-dataset/versions/1/LJSpeech-1.1/wavs\")\n",
    "BG_DIR = os.path.abspath(\"datasets/background_simplified\")\n",
    "OUT_DIR = os.path.abspath(\"mixed_up_data_talk/noisy\")\n",
    "AMPLIFICATION = [10, 15, 20]\n",
    "\n",
    "voice_files = glob.glob(os.path.join(VOICE_DIR, \"*.wav\"))\n",
    "bg_noise_type = [\"cafeteria_noises\", \"metro_noises\", \"park_noises\", \"station_noises\", \"traffic_noises\"]\n",
    "\n",
    "def mix_it_up(idx):\n",
    "    for type in bg_noise_type:\n",
    "        \n",
    "        bg_files    = glob.glob(os.path.join(BG_DIR, type, \"*.wav\"))\n",
    "\n",
    "        voice_path = random.choice(voice_files)\n",
    "        bg_path = random.choice(bg_files)\n",
    "\n",
    "        voice = AudioSegment.from_file(voice_path)\n",
    "        background = AudioSegment.from_file(bg_path)\n",
    "\n",
    "        background += random.choice(AMPLIFICATION)\n",
    "\n",
    "        combined = voice.overlay(background)\n",
    "\n",
    "        out_path = os.path.join(OUT_DIR, f\"mixed_noisy_{type}_{idx}.wav\")\n",
    "        combined.export(out_path, format = 'wav')\n",
    "\n",
    "for i in tqdm(range(70), desc=\"Creazione Noisy Set\"): mix_it_up(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "175e8b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"mixed_up_data_talk/noisy\", exist_ok = True)\n",
    "os.makedirs(\"mixed_up_data_talk/music\", exist_ok=True)\n",
    "\n",
    "BG_DIR = os.path.abspath(\"datasets/background_simplified\")\n",
    "OUT_DIR_MUSIC = os.path.abspath(\"mixed_up_data_talk/music\")\n",
    "OUT_DIR_NOISE = os.path.abspath(\"mixed_up_data_talk/noisy\")\n",
    "\n",
    "def augment_file(input_path, output_dir, sample_rate, stretch_factors, pitch_steps, amplification):\n",
    "    \n",
    "    y, sr = librosa.load(input_path, sr=sample_rate)\n",
    "    basename = os.path.splitext(os.path.basename(input_path))[0]\n",
    "    \n",
    "    ops = ['stretch', 'pitch', 'gain', 'none']\n",
    "    choice = random.choice(ops)\n",
    "    \n",
    "    if choice == 'stretch':\n",
    "        factor = random.choice(stretch_factors)\n",
    "        y_stretch = librosa.effects.time_stretch(y, rate=factor)\n",
    "        out_name = f\"{basename}_stretch{factor:.2f}.wav\"\n",
    "        sf.write(os.path.join(output_dir, out_name), y_stretch, sr)\n",
    "\n",
    "    if choice == 'pitch':\n",
    "        steps = random.choice(pitch_steps)\n",
    "        y_shift = librosa.effects.pitch_shift(y=y, sr=sr, n_steps=steps)\n",
    "        out_name = f\"{basename}_pitch{steps:+d}.wav\"\n",
    "        sf.write(os.path.join(output_dir, out_name), y_shift, sr)\n",
    "    \n",
    "    if choice == 'gain':\n",
    "        gain = random.choice(amplification)\n",
    "        y_amplify = y * gain\n",
    "        out_name = f\"{basename}_amplified_{gain:.1f}x.wav\"\n",
    "        sf.write(os.path.join(output_dir, out_name), y_amplify, sr)\n",
    "    \n",
    "    if ops == 'none': sf.write(os.path.join(output_dir, basename), y, sr)\n",
    "\n",
    "def batch_augment(input_dir, output_dir,\n",
    "                  sample_rate=44100,\n",
    "                  stretch_factors=(0.9, 1.1),\n",
    "                  pitch_steps=(-2, 2), amplification = 0):\n",
    "    \n",
    "    for f in tqdm(os.listdir(input_dir), desc=\"Augumenting Music\"):\n",
    "                inp_path = os.path.join(input_dir, f)\n",
    "                augment_file(inp_path, output_dir, sample_rate, stretch_factors, pitch_steps, amplification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "969861ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35229f8833bc4f5bb82da0d31d03b8ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Augumenting Music:   0%|          | 0/93 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b0bb8cbae2459db42983eb5ef154ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Augumenting Music:   0%|          | 0/350 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentazione completata!\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"mixed_up_data_talk/music\", exist_ok = True)\n",
    "os.makedirs(\"mixed_up_data_talk/noise_augmented\", exist_ok=True)\n",
    "\n",
    "OUT_DIR_MUSIC = os.path.abspath(\"mixed_up_data_talk/music\")\n",
    "song_path = os.path.abspath(\"datasets/music_set_wav/complete_song\")\n",
    "\n",
    "OUT_DIR_NOISE = os.path.abspath(\"mixed_up_data_talk/noise_augmented\")\n",
    "noise_path = os.path.abspath(\"mixed_up_data_talk/noisy\")\n",
    "\n",
    "sr       = 44100\n",
    "stretches = [0.8, 1.2]\n",
    "pitches  = [-3, 3]\n",
    "amplification = [-5, 1, +5]\n",
    "\n",
    "\n",
    "batch_augment(song_path, OUT_DIR_MUSIC, sr, stretches, pitches, amplification)\n",
    "batch_augment(noise_path, OUT_DIR_NOISE, sr, stretches, pitches, amplification)\n",
    "\n",
    "print(\"Augmentazione completata!\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6b06b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "import os\n",
    "import random\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def segment_file(in_path: str, out_dir: str, window_s: float, segments: int) -> None:\n",
    "    \n",
    "    audio = AudioSegment.from_file(in_path)\n",
    "    dur_ms = len(audio)\n",
    "    window_ms = int(window_s * 1000)\n",
    "    base, _ = os.path.splitext(os.path.basename(in_path))\n",
    "\n",
    "    if dur_ms < window_ms:\n",
    "        out_name = f\"{base}segment{1:03d}.wav\"\n",
    "        audio.export(os.path.join(out_dir, out_name), format=\"wav\")\n",
    "        return\n",
    "        \n",
    "    for i in range(segments):\n",
    "        start = random.randint(0, dur_ms - window_ms)\n",
    "        end = start + window_ms\n",
    "        segment = audio[start:end]\n",
    "\n",
    "        out_name = f\"{base}segment{i:03d}.wav\"\n",
    "        segment.export(os.path.join(out_dir, out_name), format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1efdad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_s = 3\n",
    "\n",
    "os.makedirs(\"mixed_up_data_talk_segmented\", exist_ok=True)\n",
    "os.makedirs(\"mixed_up_data_talk_segmented/music\", exist_ok=True)\n",
    "os.makedirs(\"mixed_up_data_talk_segmented/noisy\", exist_ok=True)\n",
    "\n",
    "output_dir_music = os.path.abspath(\"mixed_up_data_talk_segmented/music\")\n",
    "output_dir_noisy = os.path.abspath(\"mixed_up_data_talk_segmented/noisy\")\n",
    "\n",
    "music_dir = os.path.abspath(\"mixed_up_data_talk/music\")\n",
    "noisy_dir = os.path.abspath(\"mixed_up_data_talk/noise_augmented\")\n",
    "# ripetiamo per chiarezza\n",
    "\n",
    "music_files = [f for f in os.listdir(music_dir)]\n",
    "noisy_files = [f for f in os.listdir(noisy_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5103b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095378f11fc949ecb224689fdaed4f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finestratura Audio Music:   0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1844\n"
     ]
    }
   ],
   "source": [
    "for fname in tqdm(music_files, desc=\"Finestratura Audio Music\"):\n",
    "    in_path = os.path.join(music_dir,fname)\n",
    "    try:\n",
    "        segment_file(in_path, output_dir_music, win_s, random.choice([12,14,16]))\n",
    "    except Exception as e:\n",
    "            print(f\"Errore con {fname}: {e}\")\n",
    "\n",
    "music_files = [f for f in os.listdir(output_dir_music)]\n",
    "print(len(music_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a570c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1895\n"
     ]
    }
   ],
   "source": [
    "for fname in noisy_files:\n",
    "    in_path = os.path.join(noisy_dir,fname)\n",
    "    try:\n",
    "        segment_file(in_path, output_dir_noisy, win_s, 4)\n",
    "    except Exception as e:\n",
    "            print(f\"Errore con {fname}: {e}\")\n",
    "noisy_files = [f for f in os.listdir(output_dir_noisy)]\n",
    "print(len(noisy_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f296b19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset salvato in datasets/labels_mfcc_talk_segmented.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "music_dir = os.path.abspath(\"mixed_up_data_talk_segmented/music\")\n",
    "noisy_dir = os.path.abspath(\"mixed_up_data_talk_segmented/noisy\")\n",
    "\n",
    "music_files = [f for f in os.listdir(music_dir)]\n",
    "noisy_files = [f for f in os.listdir(noisy_dir)]\n",
    "# ripetiamo per chiarezza\n",
    "\n",
    "records = []\n",
    "for f in music_files:\n",
    "    records.append({f\"filepath\": os.path.join(music_dir,f), \"label\": \"music\"})\n",
    "for f in noisy_files:\n",
    "    records.append({\"filepath\": os.path.join(noisy_dir,f), \"label\": \"noisy\"})\n",
    "\n",
    "df = pd.DataFrame.from_records(records)\n",
    "\n",
    "df.to_csv(\"datasets/labels_mfcc_talk_segmented.csv\", index=False)\n",
    "print(\"Dataset salvato in datasets/labels_mfcc_talk_segmented.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
