{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7969449a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset salvato in datasets/labels_mfcc_talk.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "music_dir = os.path.abspath(\"mixed_up_data_talk/music\")\n",
    "noisy_dir = os.path.abspath(\"mixed_up_data_talk/noisy\")\n",
    "\n",
    "music_files = [f for f in os.listdir(music_dir)]\n",
    "noisy_files = [f for f in os.listdir(noisy_dir)]\n",
    "\n",
    "records = []\n",
    "for f in music_files:\n",
    "    records.append({f\"filepath\": os.path.join(music_dir,f), \"label\": \"music\"})\n",
    "for f in noisy_files:\n",
    "    records.append({\"filepath\": os.path.join(noisy_dir,f), \"label\": \"noisy\"})\n",
    "\n",
    "df = pd.DataFrame.from_records(records)\n",
    "\n",
    "df.to_csv(\"datasets/labels_mfcc_talk.csv\", index=False)\n",
    "print(\"Dataset salvato in datasets/labels_mfcc_talk.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2647d450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forza utilizzo della CPU per il train, più 'sbrigativo' che CUDA\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.config.optimizer.set_jit(False)\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "CSV_PATH   = \"datasets/labels_mfcc_talk.csv\"\n",
    "MODEL_OUT  = \"yamnet_model_small_dataset.joblib\"      # Salvo nella directory corrente, si può cambiare percorso\n",
    "SR         = 16000                      \n",
    "\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "label_map = {\"music\": 0, \"noisy\": 1}\n",
    "df[\"label_num\"] = df[\"label\"].map(label_map)\n",
    "\n",
    "file_label_list = list(zip(df[\"filepath\"].tolist(),\n",
    "                           df[\"label_num\"].tolist()))\n",
    "\n",
    "yamnet_model = hub.load(\"https://tfhub.dev/google/yamnet/1\")\n",
    "\n",
    "def extract_yamnet_embedding(wav_path, sr=16000):\n",
    "    wav, _ = librosa.load(wav_path, sr=sr, mono=True)\n",
    "\n",
    "    wav_tf = tf.convert_to_tensor(wav, dtype=tf.float32)\n",
    "\n",
    "    scores, embeddings, spectrogram = yamnet_model(wav_tf)\n",
    "\n",
    "    emb = tf.reduce_mean(embeddings, axis=0)\n",
    "    return emb.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b2a5916",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "for path, label in file_label_list:\n",
    "    emb = extract_yamnet_embedding(path)\n",
    "    X.append(emb)\n",
    "    y.append(label)\n",
    "X = np.vstack(X)\n",
    "y = np.array(y)\n",
    "\n",
    "scaler = StandardScaler().fit(X)\n",
    "\n",
    "norm = scaler.fit_transform(X)\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "X_reduced = lda.fit_transform(norm,y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_reduced, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40314df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valutazione su Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       music       1.00      1.00      1.00        13\n",
      "       noisy       1.00      1.00      1.00        71\n",
      "\n",
      "    accuracy                           1.00        84\n",
      "   macro avg       1.00      1.00      1.00        84\n",
      "weighted avg       1.00      1.00      1.00        84\n",
      "\n",
      "Matrice di Confusione:\n",
      " [[13  0]\n",
      " [ 0 71]]\n",
      "Modello YAMNet salvato in yamnet_head.joblib …\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(\n",
    "    max_iter=500,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Valutazione su Test Set:\")\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=['music','noisy']))\n",
    "print(\"Matrice di Confusione:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n",
    "print(f\"Modello YAMNet salvato in {MODEL_OUT} …\")\n",
    "joblib.dump({'pca': lda, 'clf': clf}, MODEL_OUT)\n",
    "\n",
    "def predict_noisy_probability(wav_path):\n",
    "\n",
    "    emb = extract_yamnet_embedding(wav_path).reshape(1, -1)\n",
    "    emb_scaled = scaler.transform(emb)         \n",
    "    emb_lda    = lda.transform(emb_scaled)    \n",
    "    prob_noisy = clf.predict_proba(emb_lda)[0, 1]\n",
    "    return prob_noisy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48c4f089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilità che 'audio_test/music_pure.wav' sia noisy: 0.000\n",
      "Probabilità che 'audio_test/noise_pure.wav' sia noisy: 0.992\n",
      "Probabilità che 'audio_test/voice_base_music.wav' sia noisy: 0.871\n",
      "Probabilità che 'audio_test/voice_base_pure.wav' sia noisy: 0.995\n",
      "Probabilità che 'audio_test/voice_base_noise.wav' sia noisy: 1.000\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test_files = [\n",
    "        \"audio_test/music_pure.wav\",\n",
    "        \"audio_test/noise_pure.wav\",\n",
    "        \"audio_test/voice_base_music.wav\",\n",
    "        \"audio_test/voice_base_pure.wav\",\n",
    "        \"audio_test/voice_base_noise.wav\"\n",
    "        ]\n",
    "    for test_file in test_files:\n",
    "        if os.path.exists(test_file):\n",
    "            prob = predict_noisy_probability(test_file)\n",
    "            print(f\"Probabilità che '{test_file}' sia noisy: {prob:.3f}\")\n",
    "        else:\n",
    "            print(f\"File di test non trovato: {test_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ada6e58",
   "metadata": {},
   "source": [
    "# Breve Descrizione\n",
    "In questo caso, differentemente dal modello 'large_dataset', YAMNet è stato allenato su una mole di dati più piccola ma 'tascabile', nel senso che ci veniva più comodo mostrare i ragionamenti fatti non su .csv di diversi GB ma ridotte in dimensione, il che è sicuramente meglio in termini di consegna del progetto e discussione orale. Il modello ovviamente overfitta e restituisce accuracy folli ma semplicemente perché vede pochi dati, comunque funziona abbastanza bene classificando gli embeddings di YAMNet ma perché questi sono altamente informativi. Performance più veritiere si vedonon sul modello 'large_dataset'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
